{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4535a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.transforms import Compose,ToTensor,Normalize\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "# Show 10 decimal places\n",
    "torch.set_printoptions(precision=8)\n",
    "np.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c448bc",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "<font size=2>\n",
    "    \n",
    "The original datasets **x_data** and **y_data** have the same shape which is: (32768, 30);\n",
    "    \n",
    "In order to intuitionally represent the structure of dataset, name the dimensions as:\n",
    "    \n",
    "    (32768, 30) -> (time_series, state)\n",
    "\n",
    "where **time_series** is a time serial with 32768 time epoch, for each epoch there is a **state** with 30 features, i.e. with dimension of 30;\n",
    "    \n",
    "For example, x_data[i,j] represents: j-th feature of i-th epoch;\n",
    "    \n",
    "The task is to predict $y_{k}$ with **sub-serial** $[x_{k-m}, x_{k-m+1}, ..., x_{k+m-1}, x_{k+m}]$, which is similarly shown below (**m** is the **window** of prediction and can be adjusted for better trainning):\n",
    "    \n",
    "<div>\n",
    "<img src=\"kiglis_task.png\" style=\"zoom:60%\"/>\n",
    "</div>\n",
    "    \n",
    "then input dataset **x_data** should be adjusted. The new input dataset should have shape:\n",
    "    \n",
    "    (time_epoch, window_size, state) = (32768-2m, 2m+1, 30)\n",
    "    \n",
    "and target set should be like:\n",
    "    \n",
    "    (time_epoch, state) = (32768-2m, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6ed8afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original x_data has shape of: (32768, 30)\n",
      "original y_data has shape of: (32768, 30)\n"
     ]
    }
   ],
   "source": [
    "'''load original data'''\n",
    "\n",
    "x_path = '/home/hardli/python/Fraunhofer KIT/Interview/kiglis/x_data.txt'\n",
    "y_path = '/home/hardli/python/Fraunhofer KIT/Interview/kiglis/y_data.txt'\n",
    "ori_x_data = np.array(pd.read_csv(x_path,delimiter=',',header=None))\n",
    "ori_y_data = np.array(pd.read_csv(y_path,delimiter=',',header=None))\n",
    "ori_len_seq,state_size = ori_x_data.shape\n",
    "print(\"original x_data has shape of: {}\".format(ori_x_data.shape))\n",
    "print(\"original y_data has shape of: {}\".format(ori_y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "acd868a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''normalization of data'''\n",
    "\n",
    "def normalize_dataset(data, norm=False):\n",
    "    \n",
    "    new_data = torch.from_numpy(data)\n",
    "    if norm == True:\n",
    "        mean = torch.mean(new_data, axis=0, keepdims=True)\n",
    "        std = torch.std(new_data, axis=0, keepdims=True)\n",
    "        new_data = ((new_data - mean) / std)\n",
    "        data = new_data\n",
    "    return new_data\n",
    "\n",
    "norm_x_data = normalize_dataset(ori_x_data)\n",
    "norm_y_data = normalize_dataset(ori_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42d2b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data has shape: torch.Size([32728, 41, 30])\n",
      "y_data has shape: torch.Size([32728, 30])\n"
     ]
    }
   ],
   "source": [
    "'''new data'''\n",
    "\n",
    "# m: half window size, the whole window has size of (2m+1)\n",
    "# for now set m=20\n",
    "m = 20\n",
    "# x_data: (time_epoch, window_size, state) = (32768-2m, 2m+1, 30)\n",
    "# y_data: (time_epoch, state) = (32768-2m, 30)\n",
    "# ori_len_seq,state_size = ori_x_data.shape = 32768,30\n",
    "x_data = torch.zeros(ori_len_seq-2*m,2*m+1,state_size)\n",
    "y_data = torch.zeros(ori_len_seq-2*m,state_size)\n",
    "print(\"x_data has shape: {}\".format(x_data.shape))\n",
    "print(\"y_data has shape: {}\".format(y_data.shape))\n",
    "for i,j in zip(range(x_data.shape[0]),range(m,ori_len_seq-m)):\n",
    "    x_data[i] = norm_x_data[j-m:j+m+1,:]\n",
    "    y_data[i] = norm_y_data[j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b3c1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dataset'''\n",
    "\n",
    "class kiglis_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_data, target_data):\n",
    "        self.input = input_data\n",
    "        self.target = target_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.input[idx]\n",
    "        tar = self.target[idx]\n",
    "        return inp, tar\n",
    "\n",
    "data_base = kiglis_dataset(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f29506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_loader: 154\n",
      "element in train_loader is: <class 'list'> with length 2\n",
      "one single input batch has shape torch.Size([128, 41, 30])\n",
      "one single target batch has shape torch.Size([128, 30])\n",
      "[0.5616033711743056  0.2786404945036082  0.12718694612922732\n",
      " 0.187632227457969   0.456913233017093   0.5854955938616798\n",
      " 0.5162694101777493  0.6140845782739225  0.9236624380522077\n",
      " 0.6909344911344512 ]\n",
      "tensor([0.56160336732864379883, 0.27864050865173339844, 0.12718693912029266357,\n",
      "        0.18763223290443420410, 0.45691323280334472656, 0.58549559116363525391,\n",
      "        0.51626938581466674805, 0.61408460140228271484, 0.92366242408752441406,\n",
      "        0.69093447923660278320])\n"
     ]
    }
   ],
   "source": [
    "'''data loader'''\n",
    "\n",
    "BatchSize = 128\n",
    "# split: the ratio of train set and validation set, test set is 1-train-val\n",
    "split = [0.6,0.2]\n",
    "\n",
    "Len = len(x_data)\n",
    "train_size = int(Len*split[0])\n",
    "val_size = int(Len*split[1])\n",
    "train_idx = range(train_size)\n",
    "val_idx = range(train_size, train_size+val_size)\n",
    "test_idx = range(train_size+val_size, Len)\n",
    "# split dataset into train_set, validation_set, test_set\n",
    "train_db = Subset(data_base, train_idx)\n",
    "val_db = Subset(data_base, val_idx)\n",
    "test_db = Subset(data_base, test_idx)\n",
    "\n",
    "# create data_loaders\n",
    "train_loader = DataLoader(train_db, batch_size=BatchSize, shuffle=False)\n",
    "val_loader = DataLoader(val_db, batch_size=BatchSize, shuffle=False)\n",
    "test_loader = DataLoader(test_db, batch_size=BatchSize, shuffle=False)\n",
    "\n",
    "# show structure of data_loader\n",
    "print(\"length of train_loader: {}\".format(len(train_loader)))\n",
    "element = next(iter(train_loader))\n",
    "print(\"element in train_loader is: {} with length {}\".format(type(element),len(element)))\n",
    "input_batch = element[0]\n",
    "target_batch = element[1]\n",
    "print(\"one single input batch has shape {}\".format(input_batch.shape))\n",
    "print(\"one single target batch has shape {}\".format(target_batch.shape))\n",
    "print(ori_x_data[0:41,0][:10])\n",
    "print(input_batch[0,:,0][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
